{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From speech_recognition module, import the sr utility. Instantiate the Recognizer class from the utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /Users/jigishap/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/jigishap/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jigishap/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jigishap/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jigishap/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jigishap/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = sr.Recognizer() #a collection of speech recognition functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mrecog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Records up to ``duration`` seconds of audio from ``source`` (an ``AudioSource`` instance) starting at ``offset`` (or at the beginning if not specified) into an ``AudioData`` instance, which it returns.\n",
      "\n",
      "If ``duration`` is not specified, then it will record until there is no more audio input.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/3.10.6/envs/AdvAI/lib/python3.10/site-packages/speech_recognition/__init__.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?recog.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'adjust_for_ambient_noise',\n",
       " 'dynamic_energy_adjustment_damping',\n",
       " 'dynamic_energy_ratio',\n",
       " 'dynamic_energy_threshold',\n",
       " 'energy_threshold',\n",
       " 'lasttfgraph',\n",
       " 'listen',\n",
       " 'listen_in_background',\n",
       " 'non_speaking_duration',\n",
       " 'operation_timeout',\n",
       " 'pause_threshold',\n",
       " 'phrase_threshold',\n",
       " 'recognize_amazon',\n",
       " 'recognize_api',\n",
       " 'recognize_assemblyai',\n",
       " 'recognize_azure',\n",
       " 'recognize_bing',\n",
       " 'recognize_google',\n",
       " 'recognize_google_cloud',\n",
       " 'recognize_houndify',\n",
       " 'recognize_ibm',\n",
       " 'recognize_lex',\n",
       " 'recognize_sphinx',\n",
       " 'recognize_tensorflow',\n",
       " 'recognize_vosk',\n",
       " 'recognize_whisper',\n",
       " 'recognize_whisper_api',\n",
       " 'recognize_wit',\n",
       " 'record',\n",
       " 'snowboy_wait_for_hot_word',\n",
       " 'tflabels']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(recog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the given audio file \"Recording2.wav\" - this contains a sample audio for you to get comfortable with the module, use the 'AudioFile' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = sr.AudioFile(\"Recording2.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. With this as source, 'record' the audio from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with samp as source:\n",
    "    audio = recog.record(samp) #extract audio data from the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using 'recognize_google' method, convert the audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = recog.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am so happy to make my first speech to text converter'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a function to return the text for any given audio file (.wav format) as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(file):\n",
    "    samp = sr.AudioFile(file)\n",
    "    \n",
    "    with samp as source:\n",
    "        audio = recog.record(samp)\n",
    "    \n",
    "    return recog.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Apply this function to the file 'Tap Review.wav' to extract the text from the audio review from the Amazon Tap focus group discsussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_text =  speech_to_text(\"Tap Review.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love this little Bluetooth speaker the Bluetooth connectivity is good the sound quality is amazing I listen to music on the time and I use Alexa all the time'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Pre-process the text - tokenize into individual terms using NLTKs word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'love',\n",
       " 'this',\n",
       " 'little',\n",
       " 'bluetooth',\n",
       " 'speaker',\n",
       " 'the',\n",
       " 'bluetooth',\n",
       " 'connectivity',\n",
       " 'is',\n",
       " 'good',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'quality',\n",
       " 'is',\n",
       " 'amazing',\n",
       " 'i',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'music',\n",
       " 'on',\n",
       " 'the',\n",
       " 'time',\n",
       " 'and',\n",
       " 'i',\n",
       " 'use',\n",
       " 'alexa',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(op_text.lower())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Define feature_list as list of features of the product, containing the following terms -\n",
    " - \"echo\", \"alexa\", \"music\", \"sound\", \"button\",\"bluetooth\", \"voice\", \"battery\", \"dot\", \"phone\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an earlier exercise, we had identified the top feautures for Amazon tap. This will be our list of features.\n",
    "We need to find which of these features are being talked of in this audio review of the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\"echo\", \"alexa\", \"music\", \"sound\", \"button\",\"bluetooth\", \"voice\", \"battery\", \"dot\", \"phone\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Identify which of the features are being talked of in the audio review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bluetooth', 'bluetooth', 'sound', 'music', 'alexa']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_features = [term for term in tokens if term in feature_list]\n",
    "review_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_features = list(set(review_features)) # To get unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['music', 'bluetooth', 'alexa', 'sound']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Learn how to build something with Python in 5 minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj = gTTS(text=text, lang=language, slow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj.save(\"mytext2speech.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gtts import gTTS\n",
    "\n",
    "text = 'Your sentence requiring text to speech'\n",
    "file_path = 'text.mp3'\n",
    "\n",
    "while not os.path.exists(file_path) or os.path.getsize(file_path) == 0:\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang='en', slow=False)\n",
    "        tts.save(file_path)\n",
    "    except Exception as e:\n",
    "        print(e.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
